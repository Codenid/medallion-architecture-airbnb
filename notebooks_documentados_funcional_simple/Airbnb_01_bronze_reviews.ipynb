{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto AirBnB Reviews con Datalake - Bronze\n",
    "\n",
    "**Capa:** Bronze\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "**Objetivo:** Prepara el catálogo y el esquema donde se almacenarán los datos crudos.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a279a3e9-da2c-489d-9755-17dcb84c077c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "USE CATALOG airbnb;\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS bronze\n",
    "  COMMENT 'Capa Bronze: datos crudos leídos desde el volume workspace.airbnb.reviews';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "**Objetivo:** Carga los datos crudos desde archivos JSON hacia la capa Bronze.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7864e550-dba6-4742-8a41-2c4436b355ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1 Leer JSON\n",
    "df_raw = (spark.read\n",
    "          .option(\"multiLine\", True)\n",
    "          .json(\"/Volumes/workspace/airbnb/reviews/listingsAndReviews-1.json\"))\n",
    "\n",
    "# 2 Preparar DataFrame Bronze\n",
    "df_bronze = (\n",
    "    df_raw\n",
    "    .withColumn(\"id\", F.coalesce(F.col(\"_id\"), F.md5(F.to_json(F.struct(\"*\")))))      # usa _id o genera hash\n",
    "    .withColumn(\"json_raw\", F.to_json(F.struct(\"*\")))                                 # guarda JSON completo como string\n",
    "    .withColumn(\"fecha_carga\", F.current_timestamp())\n",
    "    .withColumn(\"nombre_archivo_origen\", F.col(\"_metadata.file_path\"))\n",
    "    .withColumn(\"id_proceso\", F.lit(\"bronze_manual_load\"))\n",
    "    .select(\"id\", \"json_raw\", \"fecha_carga\", \"nombre_archivo_origen\", \"id_proceso\")   # importante\n",
    ")\n",
    "\n",
    "# 3 Crear tabla Bronze si no existe\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS airbnb.bronze.bronze_listings_raw (\n",
    "  id STRING,\n",
    "  json_raw STRING,\n",
    "  fecha_carga TIMESTAMP,\n",
    "  nombre_archivo_origen STRING,\n",
    "  id_proceso STRING\n",
    ") USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# 4 Escribir los datos\n",
    "(df_bronze.write\n",
    " .format(\"delta\")\n",
    " .mode(\"append\")\n",
    " .saveAsTable(\"airbnb.bronze.bronze_listings_raw\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Airbnb_01_bronze_reviews",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
