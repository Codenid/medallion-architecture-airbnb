{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c702f76-7932-403d-b354-8fdbebfe458f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Modelo de aprendizaje supervisado para la predicción del precio de alojamientos en Airbnb a partir de características de oferta y reputación del anfitrión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a151ddd-bcbe-408f-8c7f-148aa2d45019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**1. Extracción de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 1\n",
    "**Objetivo funcional:** Carga los datos finales de entrenamiento desde la capa Gold..\n",
    "**Entradas/Salidas:** airbnb.gold.price_features\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "aa43f361-1deb-49b8-8d95-0ef2a39bb2a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AirbnbPriceModel\").getOrCreate()\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM airbnb.gold.price_features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d07c064d-3389-4f90-b53c-9268357a0d95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2. Limpieza y selección**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 2\n",
    "**Objetivo funcional:** Carga los datos finales de entrenamiento desde la capa Gold..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3a80cdb1-9d7e-4d91-aacb-7a85ea5fa403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_clean = (\n",
    "    df\n",
    "    .filter(col(\"price\").isNotNull())\n",
    "    .filter(col(\"price\") > 0)\n",
    "    .dropna(subset=[\"accommodates\", \"bedrooms\", \"bathrooms\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "458a1b43-69e4-446b-b763-f2eacc483b21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3. Preparación de features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 3\n",
    "**Objetivo funcional:** Prepara y entrena el modelo predictivo usando los datos de la capa Gold..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a815889b-a8c0-46f0-bca7-e4f7fe452ea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# convertir a string solo la columna conflictiva\n",
    "df_clean = df_clean.withColumn(\"host_is_superhost\", col(\"host_is_superhost\").cast(\"string\"))\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cat_cols = [\"country\", \"city\", \"neighborhood\", \"host_is_superhost\"]\n",
    "num_cols = [\n",
    "    \"accommodates\", \"bedrooms\", \"bathrooms\", \"beds\",\n",
    "    \"review_scores_rating\", \"number_of_reviews\", \"host_total_listings_count\",\n",
    "    \"host_response_rate\", \"amenities_count\", \"latitude\", \"longitude\",\n",
    "    \"days_since_first_review\", \"days_since_last_review\", \"reviews_per_month_der\"\n",
    "]\n",
    "bin_cols = [c for c in df.columns if c.startswith(\"has_\") or c.startswith(\"is_\")]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\") for c in cat_cols]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=num_cols + [f\"{c}_idx\" for c in cat_cols] + bin_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "data = pipeline.fit(df_clean).transform(df_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f9ce6a-296f-4c27-b954-cdd8b8b0655b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**4. División train/test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 4\n",
    "**Objetivo funcional:** Paso funcional dentro del proceso de entrenamiento o evaluación del modelo..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9f9a4f95-4b21-4104-8ec5-f86c89d81c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b9f1cea-7bb2-4707-ab52-b058aa647cc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**5. Entrenamiento (modelo base: Random Forest Regressor)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 5\n",
    "**Objetivo funcional:** Carga los datos finales de entrenamiento desde la capa Gold..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5ce69fd0-839f-4f28-b32c-213e3473012c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# 1  Asegurar double (ya lo tienes, pero lo dejamos robusto)\n",
    "for c in assembler.getInputCols():\n",
    "    data = data.withColumn(c, col(c).cast(DoubleType()))\n",
    "\n",
    "# 2  Reemplazar NaN por 0 (solo para columnas numéricas)\n",
    "data = data.na.fill(0, subset=assembler.getInputCols())\n",
    "\n",
    "# 3  Si existe columna 'features' anterior, eliminarla\n",
    "if 'features' in data.columns:\n",
    "    data = data.drop('features')\n",
    "\n",
    "# 4  Ensamblar nuevamente\n",
    "data = assembler.transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 6\n",
    "**Objetivo funcional:** Prepara y entrena el modelo predictivo usando los datos de la capa Gold..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "baedac4d-0b42-4f7b-80ce-8849f8ccf03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "train, test = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"price\", numTrees=100)\n",
    "model = rf.fit(train)\n",
    "\n",
    "preds = model.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(preds, {evaluator.metricName: \"rmse\"})\n",
    "r2 = evaluator.evaluate(preds, {evaluator.metricName: \"r2\"})\n",
    "print(f\"RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35a7b3f3-493d-4f70-a0e2-7d5f18d746eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**6. Interpretación de resultados**\n",
    "\n",
    "- RMSE mide el error promedio en euros o USD por noche.\n",
    "- R² indica cuánta variabilidad del precio explica el modelo.\n",
    "- Se puede analizar la importancia de las variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 7\n",
    "**Objetivo funcional:** Paso funcional dentro del proceso de entrenamiento o evaluación del modelo..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ed75e4c6-f06e-45a1-895d-9720907cf803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    \"feature\": assembler.getInputCols(),\n",
    "    \"importance\": model.featureImportances.toArray()\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "display(importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bb1c0ed-44b8-42f4-b039-7beaff290a19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**7. Exportar el dataset - gold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloque 8\n",
    "**Objetivo funcional:** Paso funcional dentro del proceso de entrenamiento o evaluación del modelo..\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "12d5c80b-dfc8-49d6-9ea2-bb7aaa7c886c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1 Prepara tu dataset limpio\n",
    "cols = [\"price\"] + assembler.getInputCols()\n",
    "df_final = data.select(*cols).na.fill(0)\n",
    "\n",
    "# 2 Muestra los datos en la interfaz\n",
    "display(df_final)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Airbnb_04_price_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
